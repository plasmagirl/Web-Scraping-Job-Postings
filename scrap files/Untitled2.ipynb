{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['''Data Scientist Position Summary The Data Scientist applies machine learning and statistical techniques. \n",
    "        The Data Scientist will be responsible for exploring and creating compelling visualizations of new datasets, \n",
    "        identify key features and engineer new ones to be used in modeling, and discover the modeling approaches that \n",
    "        deliver the best results based on appropriate evaluation metrics. Essential Responsibilities Collaborate with \n",
    "        teams across the business to translate their needs or challenges into machine learning or statistical problems\n",
    "        Support the development of data products through exploratory data analysis, feature engineering and model \n",
    "        building Effectively communicate experiments, models and analytics outputs with partners Other duties as \n",
    "        assigned Minimum Experience and Qualifications Bachelor’s Degree in computer science or a quantitative \n",
    "        discipline Two (2) to Three (3) year of relevant industry experience Proficiency in Python, SQL, git and \n",
    "        common data science and machine learning libraries Experience building machine learning models Able to write \n",
    "        production quality code and be familiar with software engineering best practices, including testing and \n",
    "        version control Ability to communicate their findings to both technical and non-technical audience \n",
    "        Preferred Experience and Qualifications Advanced degree in computer science or a quantitative discipline \n",
    "        Experience applying various data science techniques such as: Forecasting, Recommendation Systems, A/B Testing,\n",
    "        Logistics Optimization, Churn Analysis, Segmentation Analysis, and Deep Learning Experience using Databricks, \n",
    "        PySpark / Spark, Snowflake, dbt, Azure Cloud Job Type: Full-time Pay: $90,000.00 - $140,000.00 per year \n",
    "        Schedule: Monday to Friday Hiring Lab Career Advice Browse Jobs Browse Companies Salaries Find Certifications \n",
    "        Indeed Events Work at Indeed Countries About Help Center © 2020 Indeed Do Not Sell My Personal Information \n",
    "        Privacy Center Cookies Privacy Terms''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words={'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '140',\n",
       " '2020',\n",
       " '90',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'about',\n",
       " 'across',\n",
       " 'advanced',\n",
       " 'advice',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'applies',\n",
       " 'applying',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'as',\n",
       " 'assigned',\n",
       " 'at',\n",
       " 'audience',\n",
       " 'azure',\n",
       " 'bachelor',\n",
       " 'based',\n",
       " 'be',\n",
       " 'best',\n",
       " 'both',\n",
       " 'browse',\n",
       " 'building',\n",
       " 'business',\n",
       " 'career',\n",
       " 'center',\n",
       " 'certifications',\n",
       " 'challenges',\n",
       " 'churn',\n",
       " 'cloud',\n",
       " 'code',\n",
       " 'collaborate',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'companies',\n",
       " 'compelling',\n",
       " 'computer',\n",
       " 'control',\n",
       " 'cookies',\n",
       " 'countries',\n",
       " 'creating',\n",
       " 'data',\n",
       " 'databricks',\n",
       " 'datasets',\n",
       " 'dbt',\n",
       " 'deep',\n",
       " 'degree',\n",
       " 'deliver',\n",
       " 'development',\n",
       " 'discipline',\n",
       " 'discover',\n",
       " 'do',\n",
       " 'duties',\n",
       " 'effectively',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'essential',\n",
       " 'evaluation',\n",
       " 'events',\n",
       " 'experience',\n",
       " 'experiments',\n",
       " 'exploratory',\n",
       " 'exploring',\n",
       " 'familiar',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'find',\n",
       " 'findings',\n",
       " 'for',\n",
       " 'forecasting',\n",
       " 'friday',\n",
       " 'full',\n",
       " 'git',\n",
       " 'help',\n",
       " 'hiring',\n",
       " 'identify',\n",
       " 'in',\n",
       " 'including',\n",
       " 'indeed',\n",
       " 'industry',\n",
       " 'information',\n",
       " 'into',\n",
       " 'job',\n",
       " 'jobs',\n",
       " 'key',\n",
       " 'lab',\n",
       " 'learning',\n",
       " 'libraries',\n",
       " 'logistics',\n",
       " 'machine',\n",
       " 'metrics',\n",
       " 'minimum',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'monday',\n",
       " 'my',\n",
       " 'needs',\n",
       " 'new',\n",
       " 'non',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'ones',\n",
       " 'optimization',\n",
       " 'or',\n",
       " 'other',\n",
       " 'outputs',\n",
       " 'partners',\n",
       " 'pay',\n",
       " 'per',\n",
       " 'personal',\n",
       " 'position',\n",
       " 'practices',\n",
       " 'preferred',\n",
       " 'privacy',\n",
       " 'problems',\n",
       " 'production',\n",
       " 'products',\n",
       " 'proficiency',\n",
       " 'pyspark',\n",
       " 'python',\n",
       " 'qualifications',\n",
       " 'quality',\n",
       " 'quantitative',\n",
       " 'recommendation',\n",
       " 'relevant',\n",
       " 'responsibilities',\n",
       " 'responsible',\n",
       " 'results',\n",
       " 'salaries',\n",
       " 'schedule',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'segmentation',\n",
       " 'sell',\n",
       " 'snowflake',\n",
       " 'software',\n",
       " 'spark',\n",
       " 'sql',\n",
       " 'statistical',\n",
       " 'such',\n",
       " 'summary',\n",
       " 'support',\n",
       " 'systems',\n",
       " 'teams',\n",
       " 'technical',\n",
       " 'techniques',\n",
       " 'terms',\n",
       " 'testing',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'three',\n",
       " 'through',\n",
       " 'time',\n",
       " 'to',\n",
       " 'translate',\n",
       " 'two',\n",
       " 'type',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'version',\n",
       " 'visualizations',\n",
       " 'will',\n",
       " 'with',\n",
       " 'work',\n",
       " 'write',\n",
       " 'year']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.07342231],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.11013346],\n",
       "        [0.03671115],\n",
       "        [0.51395617],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.11013346],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.25697808],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.22026693],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.14684462],\n",
       "        [0.03671115],\n",
       "        [0.11013346],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.18355577],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.14684462],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.11013346],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.14684462],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.14684462],\n",
       "        [0.11013346],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.22026693],\n",
       "        [0.07342231],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.25697808],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.11013346],\n",
       "        [0.03671115],\n",
       "        [0.03671115],\n",
       "        [0.07342231]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].T.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ' '.join(temp_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = ['''data scientist position summary data scientist applies machine learning statistical techniques data \n",
    "         scientist responsible exploring creating compelling visualizations new datasets identify key features \n",
    "         engineer new ones used modeling discover modeling approaches deliver best results based appropriate \n",
    "         evaluation metrics essential responsibilities collaborate teams across business translate needs challenges \n",
    "         machine learning statistical problems support development data products exploratory data analysis feature \n",
    "         engineering model building effectively communicate experiments models analytics outputs partners duties \n",
    "         assigned minimum experience qualifications bachelor degree computer science quantitative discipline two 2 \n",
    "         three 3 year relevant industry experience proficiency python sql git common data science machine learning \n",
    "         libraries experience building machine learning models able write production quality code familiar software \n",
    "         engineering best practices including testing version control ability communicate findings technical audience \n",
    "         preferred experience qualifications advanced degree computer science quantitative discipline experience \n",
    "         applying various data science techniques forecasting recommendation systems testing logistics optimization \n",
    "         churn analysis segmentation analysis deep learning experience using databricks pyspark spark snowflake dbt \n",
    "         azure cloud job type pay per year schedule monday friday hiring lab career advice''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'across',\n",
       " 'advanced',\n",
       " 'advice',\n",
       " 'analysis',\n",
       " 'analytics',\n",
       " 'applies',\n",
       " 'applying',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'assigned',\n",
       " 'audience',\n",
       " 'azure',\n",
       " 'bachelor',\n",
       " 'based',\n",
       " 'best',\n",
       " 'building',\n",
       " 'business',\n",
       " 'career',\n",
       " 'challenges',\n",
       " 'churn',\n",
       " 'cloud',\n",
       " 'code',\n",
       " 'collaborate',\n",
       " 'common',\n",
       " 'communicate',\n",
       " 'compelling',\n",
       " 'computer',\n",
       " 'control',\n",
       " 'creating',\n",
       " 'data',\n",
       " 'databricks',\n",
       " 'datasets',\n",
       " 'dbt',\n",
       " 'deep',\n",
       " 'degree',\n",
       " 'deliver',\n",
       " 'development',\n",
       " 'discipline',\n",
       " 'discover',\n",
       " 'duties',\n",
       " 'effectively',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'essential',\n",
       " 'evaluation',\n",
       " 'experience',\n",
       " 'experiments',\n",
       " 'exploratory',\n",
       " 'exploring',\n",
       " 'familiar',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'findings',\n",
       " 'forecasting',\n",
       " 'friday',\n",
       " 'git',\n",
       " 'hiring',\n",
       " 'identify',\n",
       " 'including',\n",
       " 'industry',\n",
       " 'job',\n",
       " 'key',\n",
       " 'lab',\n",
       " 'learning',\n",
       " 'libraries',\n",
       " 'logistics',\n",
       " 'machine',\n",
       " 'metrics',\n",
       " 'minimum',\n",
       " 'model',\n",
       " 'modeling',\n",
       " 'models',\n",
       " 'monday',\n",
       " 'needs',\n",
       " 'new',\n",
       " 'ones',\n",
       " 'optimization',\n",
       " 'outputs',\n",
       " 'partners',\n",
       " 'pay',\n",
       " 'per',\n",
       " 'position',\n",
       " 'practices',\n",
       " 'preferred',\n",
       " 'problems',\n",
       " 'production',\n",
       " 'products',\n",
       " 'proficiency',\n",
       " 'pyspark',\n",
       " 'python',\n",
       " 'qualifications',\n",
       " 'quality',\n",
       " 'quantitative',\n",
       " 'recommendation',\n",
       " 'relevant',\n",
       " 'responsibilities',\n",
       " 'responsible',\n",
       " 'results',\n",
       " 'schedule',\n",
       " 'science',\n",
       " 'scientist',\n",
       " 'segmentation',\n",
       " 'snowflake',\n",
       " 'software',\n",
       " 'spark',\n",
       " 'sql',\n",
       " 'statistical',\n",
       " 'summary',\n",
       " 'support',\n",
       " 'systems',\n",
       " 'teams',\n",
       " 'technical',\n",
       " 'techniques',\n",
       " 'testing',\n",
       " 'three',\n",
       " 'translate',\n",
       " 'two',\n",
       " 'type',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'version',\n",
       " 'visualizations',\n",
       " 'write',\n",
       " 'year']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text1)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebScraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
